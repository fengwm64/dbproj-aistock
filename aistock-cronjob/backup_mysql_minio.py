import subprocess
import gzip
import boto3
import datetime
import os
import tempfile
from dotenv import load_dotenv

load_dotenv(override=True)

DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")

MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY")
BUCKET_NAME = os.getenv("BUCKET_NAME")

BACKUP_DIR = os.getenv("BACKUP_DIR", "/tmp/db_backups")


def run_backup():
    os.makedirs(BACKUP_DIR, exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    sql_path = os.path.join(BACKUP_DIR, f"{DB_NAME}_{timestamp}.sql")
    gz_path = sql_path + ".gz"

    print(f"ğŸ“¦ å¼€å§‹å¤‡ä»½æ•°æ®åº“ {DB_NAME} -> {gz_path}")

    # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¼ å¯†ç ï¼Œé¿å…åœ¨å‘½ä»¤è¡Œä¸­æš´éœ²æˆ–è¯¯å†™å¼•å·
    env = os.environ.copy()
    if DB_PASS:
        env["MYSQL_PWD"] = DB_PASS

    dump_cmd = [
        "mysqldump",
        "-h", DB_HOST,
        "-u", DB_USER,
        "--single-transaction",
        "--quick",
        "--routines",
        "--triggers",
        "--databases", DB_NAME,
        "--ssl=0"
    ]

    # å…ˆæŠŠ mysqldump è¾“å‡ºå†™å…¥ä¸´æ—¶ .sql æ–‡ä»¶ï¼ˆé¿å…ä¸€æ¬¡æ€§å ç”¨å†…å­˜ï¼‰
    try:
        with open(sql_path, "wb") as sql_file:
            result = subprocess.run(
                dump_cmd,
                stdout=sql_file,
                stderr=subprocess.PIPE,
                env=env
            )
        if result.returncode != 0:
            err = result.stderr.decode(errors="replace")
            print("âŒ mysqldump å¤±è´¥ï¼Œreturncode:", result.returncode)
            print("âŒ stderr:", err)
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ä¸å®Œæ•´æ–‡ä»¶
            if os.path.exists(sql_path):
                os.remove(sql_path)
            return None

        # å‹ç¼©
        with open(sql_path, "rb") as f_in, gzip.open(gz_path, "wb") as f_out:
            while True:
                chunk = f_in.read(8192)
                if not chunk:
                    break
                f_out.write(chunk)
        # åˆ é™¤åŸå§‹ .sql æ–‡ä»¶
        os.remove(sql_path)
        print("âœ… æ•°æ®åº“å¤‡ä»½æˆåŠŸ")
    except FileNotFoundError as e:
        print("âŒ æ‰¾ä¸åˆ° mysqldumpï¼Œå¯æ‰§è¡Œæ–‡ä»¶æœªå®‰è£…æˆ–ä¸åœ¨ PATHï¼š", e)
        return None
    except Exception as e:
        print("âŒ å¤‡ä»½è¿‡ç¨‹ä¸­å‡ºé”™:", e)
        # å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(sql_path):
            os.remove(sql_path)
        if os.path.exists(gz_path):
            os.remove(gz_path)
        return None

    # ä¸Šä¼ åˆ° MinIO
    try:
        from botocore.config import Config
        s3 = boto3.client(
            "s3",
            endpoint_url=MINIO_ENDPOINT,
            aws_access_key_id=MINIO_ACCESS_KEY,
            aws_secret_access_key=MINIO_SECRET_KEY,
            config=Config(s3={'addressing_style': 'path'})
        )

        object_name = os.path.basename(gz_path)
        s3.upload_file(gz_path, BUCKET_NAME, object_name)
        print(f"âœ… å·²ä¸Šä¼ åˆ° MinIO: {BUCKET_NAME}/{object_name}")

        # ä¸Šä¼ æˆåŠŸååˆ é™¤æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
        os.remove(gz_path)
        return object_name
    except Exception as e:
        print("âŒ ä¸Šä¼  MinIO å¤±è´¥:", e)
        # ä¿ç•™æœ¬åœ°æ–‡ä»¶ä»¥ä¾¿æ’æŸ¥
        return None


if __name__ == "__main__":
    run_backup()
